
---

## 빅데이터의 주요 개념 정리

#### 1. 고차원 데이터 (High Dimensional Data)
- **정의**: 관측값(observations) 하나가 매우 많은 특성(features, 열/columns)으로 이루어진 데이터  
- **예시**: 유전자 데이터(수천~수만 개의 유전자), 이미지 데이터(픽셀 수만큼 특성)
- **특징**:  
  - 분석이 어렵고, 차원의 저주(Curse of Dimensionality) 문제가 발생할 수 있음
#### 2. 그래프(Graphs)
- **정의**: 데이터 간의 관계를 표현하는 구조
- **구성요소**:
  - **노드(Node)**: 하나의 데이터 포인트, 또는 여러 특성의 집합  
    - 예: 사람, 웹페이지, 상품 등
  - **엣지(Edge)**: 노드 간의 연결(관계, 상호작용)
    - 예: 친구 관계, 하이퍼링크, 구매 이력 등
- **활용**: 소셜 네트워크, 추천 시스템, 네트워크 분석 등
#### 3. 무한 데이터 (Infinite Data)
- **정의**: 데이터가 끝없이 생성되는 환경
- **예시**:  
  - **데이터 스트림(Data Stream)**: 실시간으로 계속 들어오는 데이터  
    - 예: 센서 데이터, 실시간 로그, 트위터 등
- **특징**:  
  - 데이터를 모두 저장하지 않고, 메모리 상에서 실시간으로 처리  
  - 저장 공간의 한계로 인해 일부만 저장하거나 요약해서 사용
#### 4. 라벨링된 데이터 (Labeled Data)
- **정의**: 각 데이터에 정답(라벨)이 붙어 있는 데이터
- **활용**:  
  - **분류(Classification)**: 입력 데이터가 어떤 카테고리에 속하는지 예측  
    - 예: 스팸 메일 분류, 이미지 속 객체 인식 등
- **비교**: 라벨이 없는 데이터는 비지도 학습(Clustering 등)에 사용

---
#### 5. 데이터 파이프라인 (Data Pipeline)
- **정의**: 데이터의 수집, 저장, 처리, 분석, 시각화 등 일련의 과정을 자동화·연결한 흐름 또는 시스템  
- **주요 단계**:
  1. **데이터 수집**  
     - 다양한 소스(센서, 로그, 웹, DB 등)에서 원천 데이터 획득  
     - 예: 크롤링, API, 실시간 스트리밍 등
  2. **데이터 저장**  
     - 수집된 데이터를 저장소에 적재  
     - 예: 데이터베이스, 데이터 웨어하우스, 데이터 레이크 등
  3. **데이터 처리 및 정제**  
     - 결측치 처리, 이상치 제거, 변환, 통합 등 데이터 품질 개선  
     - 배치 처리(일괄) 또는 스트림 처리(실시간)
  4. **데이터 분석 및 모델링**  
     - 통계 분석, 머신러닝, 시각화 등 다양한 분석 기법 적용
  5. **결과 활용 및 시각화**  
     - 대시보드, 리포트, 알림 등으로 결과 전달 및 의사결정 지원

- **파이프라인의 특징**:  
  - 각 단계가 자동화되어 반복적이고 대용량 데이터 처리에 적합  
  - 확장성(Scale-out), 신뢰성(Reliability), 실시간성(Real-time) 등 요구  
  - 오픈소스 및 클라우드 기반 도구(예: Apache Airflow, Spark, Kafka, AWS Glue 등)로 구현 가능

> [!tip]  
> **데이터 파이프라인은 빅데이터 분석의 핵심 인프라**로, 데이터 흐름을 체계적으로 관리하고 분석 효율을 높여줍니다.

---
