
---

- **IO Bound(입출력 제한)**: 디스크 읽기/쓰기가 전체 성능의 주요 **보틀넥(bottleneck)**이 됨
- **보틀넥(bottleneck)**: 시스템 전체 처리 속도를 제한하는 주요 원인, 여기서는 디스크 IO가 해당
- **IO Bound** 상황에서는 디스크 속도가 전체 작업 시간 결정

---

#### 클러스터 구조의 한계점 (IO Cluster Computing Challenges)

- **노드 장애**  
  - 대규모 클러스터에서는 노드 장애가 빈번하게 발생 (예: 1,000개 중 1개 노드가 하루에 장애)
- **데이터 중복 필요**  
  - 장애 대비를 위해 데이터 복제 및 중복 저장 필요 → 저장 공간 증가
- **네트워크 병목**  
  - 네트워크 대역폭이 제한적 (일반적으로 1~10Gb/s)  
  - 데이터 이동 시 네트워크가 성능의 병목이 됨
- **계산 위치 문제**  
  - 데이터를 노드로 옮기기보다, 계산을 데이터가 있는 노드에서 수행해야 효율적
- **분산 프로그래밍의 복잡성**  
  - 전통적인 분산 프로그래밍은 구현이 복잡하고 일관성이 부족함
- **효율적인 분산 시스템 필요**  
  - 쉽게 분산 가능한 프로그래밍 시스템의 필요성 대두

> 요약: 클러스터 환경에서는 노드 장애, 데이터 중복, 네트워크 병목, 분산 프로그래밍의 복잡성 등 다양한 한계점이 존재하며, 이를 극복하기 위한 효율적인 분산 시스템 설계가 중요함.  
> **해결책:** 이러한 한계점을 해결하기 위해 HDFS(분산 파일 시스템)와 MapReduce(분산 처리 프레임워크)와 같은 기술이 도입되어, 데이터의 안정적 저장과 효율적인 분산 처리를 지원함.

---
#### 하둡 이후 분산 파일 시스템의 주요 구성 요소 (첨부 이미지 참고)

- **Chunk 서버 (Data Node)**
  - 파일은 연속적인 청크(chunk) 단위로 분할되어 저장됨
  - 각 청크의 크기는 일반적으로 16~64MB로 설정됨
  - 각 청크는 보통 2~3회 복제되어 여러 서버에 저장됨
  - 복제본은 서로 다른 랙(rack)에 분산 저장하여 동일 장애로 인한 데이터 손실을 방지함

- **네임노드 (Name Node, aka Master Node)**
  - 파일이 어디에 저장되어 있는지에 대한 메타데이터(위치 정보 등)를 관리함
  - 네임노드는 장애 대비를 위해 복제되거나 분산 저장될 수 있음

- **클라이언트 라이브러리 (Client library for file access)**
  - 클라이언트는 네임노드에 접속해 어떤 청크 서버에 데이터가 저장되어 있는지 정보를 얻음
  - 실제 데이터 접근은 클라이언트가 직접 청크 서버에 연결하여 수행함

> **정리:**  
> - 하둡 이후의 분산 파일 시스템은 파일을 여러 청크로 나누고, 각 청크를 여러 번 복제하여 신뢰성과 장애 대응력을 높임  
> - 네임노드는 파일의 메타데이터를 관리하며, 클라이언트는 네임노드를 통해 청크 서버 위치를 확인한 뒤 직접 데이터에 접근  
> - 이러한 구조는 대규모 데이터 환경에서 효율적이고 안정적인 파일 저장 및 접근을 가능하게 함

---

#### MapReduce란 무엇인가?

MapReduce는 대용량 데이터를 효율적으로 처리하기 위한 **프로그래밍 스타일**이자, 이를 분산 환경에서 실행하는 **시스템**을 의미합니다. 첨부 이미지를 참고하여 아래와 같이 정리할 수 있습니다.

1. **프로그래밍 스타일로서의 MapReduce**
   - 입력 데이터를 여러 청크(chunk)로 나누어 **map 작업**을 수행합니다.
   - 그 결과를 **키(key)별로 그룹화(group by keys)** 합니다.
   - 그룹화된 데이터를 대상으로 **reduce 작업**을 수행하여 최종 결과를 만듭니다.
   - 이 과정은 리눅스의 파이프(`|`) 명령어와 유사하게, 앞 단계의 출력을 다음 단계의 입력으로 넘기는 방식입니다.
   - 예시: 단어 개수 세기(word count)
     ```
     tokenize(document) | sort | uniq -c
     ```
     - `tokenize(document)`: 문서를 단어 단위로 분리
     - `sort`: 단어를 정렬
     - `uniq -c`: 각 단어의 등장 횟수 세기

2. **분산 시스템으로서의 MapReduce**
   - MapReduce 스타일의 프로그램을 **분산 파일 시스템**(예: HDFS) 위에서 자동으로 분산 실행해주는 시스템입니다.
   - 대표적인 예시로 Google의 내부 MapReduce, Apache Hadoop의 mapreduce(hdfs와 함께 사용) 등이 있습니다.

> **정리:**  
> - MapReduce는 "입력 → map → 그룹화 → reduce → 출력"의 구조로 대용량 데이터 처리를 단순화합니다.  
> - 리눅스 파이프라인처럼 각 단계가 연결되어 동작하며, 분산 시스템에서는 이 과정을 여러 서버에 자동으로 분산시켜 처리합니다.  
> - 실제로는 tokenize, sort, uniq -c와 같은 명령어 조합이 MapReduce의 개념을 잘 보여줍니다.

---

[[2 하둡 및 분산 아키텍쳐.pdf#page=33|2 하둡 및 분산 아키텍쳐, p.33]]

> **MapReduce에서 key의 메모리 상주와 관리의 중요성 정리 + 블록(고정크기) 단위로 읽는 이유**

- 위 그림처럼, MapReduce는 입력 데이터를 여러 청크로 나누어 각각 **Map task**에서 (key, value) 쌍으로 변환합니다.
- 그 다음, 같은 key를 가진 값들끼리 **Group by keys** 단계에서 모이게 되는데, 이때 **key들이 메모리에 올라가서 관리**됩니다.
- Reduce task는 메모리에 올라온 key별로 데이터를 처리하여 최종 결과를 만듭니다.

- **중요 포인트:**  
  - Group by keys 단계에서 key들이 메모리에 상주하게 되므로, key의 개수가 너무 많거나 key가 너무 커지면 메모리 부족 문제가 발생할 수 있습니다.
  - 따라서, key의 수를 적절히 제한하거나, key를 효율적으로 관리하는 것이 MapReduce 성능과 안정성에 매우 중요합니다.
  - 실제로는 task가 먼저 끝난 순서대로 key가 메모리에 올라오고, Reduce task가 이를 받아서 원하는 값을 도출합니다.

- **쉽게 말해:**  
  - "MapReduce에서 key는 중간 결과를 묶는 기준이자, 메모리에서 효율적으로 관리해야 하는 중요한 데이터 단위"입니다.
  - key 관리가 잘못되면 전체 작업이 느려지거나 실패할 수 있으니, key의 설계와 분포에 신경 써야 합니다.

---

> **왜 데이터를 블록(고정크기) 단위로 읽어야 할까?**

- 분산 파일 시스템(HDFS 등)이나 MapReduce에서 데이터를 읽을 때는 항상 **블록(고정크기, 예: 64MB)** 단위로 읽습니다.
- **이유:**  
  - 데이터를 미리 예측하거나 추정해서 효율적으로 처리하기 위함입니다.
  - 만약 파일 전체를 한 번에 읽거나, 크기가 들쭉날쭉한 단위로 읽으면, 어느 서버에 얼마만큼의 데이터를 분산시켜야 할지 예측이 어렵고, 네트워크/디스크 자원도 비효율적으로 사용됩니다.


- **정리:**  
  - "블록(고정크기) 단위로 읽는 것은 데이터 분산, 예측, 자원 효율, 장애 대응 등 여러 면에서 필수적이며, 대용량 데이터 환경에서 안정적이고 빠른 처리를 가능하게 한다"라고 이해하면 쉽습니다.

---
> **참고: Hadoop에서 `crew`(queue, 크루 등) 구조를 사용하면?**

- 데이터를 처리할 때 `crew`(큐, 크루 등) 구조를 사용하면, 새로운 데이터가 들어올 때마다 끝에 빠르게 append(추가)할 수 있습니다.
- 즉, 데이터가 순차적으로 계속 붙으면서 처리되기 때문에 **쓰기 속도가 매우 빠르다**는 장점이 있습니다.
- 이런 구조는 대용량 데이터 처리에서 효율적이며, MapReduce나 분산 시스템에서 데이터 수집/적재 시 자주 활용됩니다.

- **정리:**  
  - crew(큐, 크루 등) 구조를 쓰면 데이터가 끝에 빠르게 append되어, 대량의 데이터를 신속하게 저장하고 처리할 수 있습니다.

---
> **파이썬에서 iterator와 yield 개념 쉽게 정리 (이미지 예시코드 기반)**

- **Iterator란?**
  - 리스트, 튜플 등 컬렉션에서 데이터를 하나씩 꺼낼 수 있게 해주는 객체입니다.
  - `__iter__()`와 `__next__()` 메서드를 가지고 있으며, for문 내부적으로도 iterator를 사용합니다.

- **yield와 generator란?**
  - 함수에서 return 대신 yield를 사용하면, 값을 하나씩 "생산"하는 generator(제너레이터) 객체가 만들어집니다.
  - generator는 모든 값을 한 번에 메모리에 올리지 않고, 필요할 때마다 하나씩 생성하므로 대용량 데이터 처리에 효율적입니다.

- **이미지 예시코드로 설명**
  - 아래는 피보나치 수열을 생성하는 두 가지 방식의 예시입니다.

  1. **generator(yield 사용) 버전**
      ```python
      def fibon(n):
          a = b = 1
          for i in range(n):
              yield a
              a, b = b, a + b

      for x in fibon(1000000):
          print(x)
      ```
      - `yield`를 사용해 값을 하나씩 반환합니다.
      - for문에서 generator를 순회하며, 메모리에 모든 값을 저장하지 않고 필요할 때마다 값을 생성합니다.

  2. **리스트에 모두 저장하는 버전**
      ```python
      def fibon(n):
          a = b = 1
          result = []
          for i in range(n):
              result.append(a)
              a, b = b, a + b
          return result

      for x in fibon(1000000):
          print(x)
      ```
      - 모든 값을 리스트에 저장한 뒤 한 번에 반환합니다.
      - 데이터가 많아질수록 메모리 사용량이 커집니다.

- **정리**
  - iterator는 컬렉션을 순회할 수 있게 해주는 객체입니다.
  - yield를 사용하면 generator를 만들 수 있고, for문 없이도 next()로 값을 하나씩 꺼낼 수 있습니다.
  - generator는 대용량 데이터 처리에 매우 유용하며, 메모리 효율성이 높습니다.

---
