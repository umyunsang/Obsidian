# 소셜 비디오 빅데이터 실시간 처리 플랫폼 — 최종 보고서

작성자: (1705817 / 엄윤상)
제출일: 2025-12-19 까지
과목/과제: 빅데이터 분석 — 개별과제(1~5 통합 보고)

## 1. 문제 정의·목표

### 1.1 배경과 문제 정의
유튜브를 포함한 소셜 비디오 플랫폼에서는 대규모의 비정형 이벤트(영상 메타데이터, 댓글/자막, 사용자 상호작용 등)가 초당 수천~수만 건 발생한다. 이러한 데이터는 다음과 같은 이유로 분석 난이도가 높다.
- 데이터 특성: 불완전/지연 이벤트, 중복 발생, 급격한 트래픽 변동(버스팅)
- 처리 요구: 실시간성(지연 최소화), 정확성(중복 제거/지연 허용), 확장성(증가하는 소스/피처)
- 모델링 난제: 다목적 최적화(정확도·지연·비용·해석성 간 상충), 분포 기반 임계치 설정의 동적성

기존 배치 중심 파이프라인은 실시간 대응과 비용 측면에서 한계가 있으며, 단일 모델·단일 지표 기반 선택은 운영 환경에 부적합하다. 또한 초기에 모든 기능을 완제품 수준으로 구현하려다가 일정과 품질을 놓치는 문제가 반복된다.

### 1.2 목표
본 프로젝트의 목표는 “점진적 제품화” 전략으로 다음을 달성하는 것이다.
- 데이터 수집→정제→피처/라벨→학습/선정→서빙 전체 파이프라인을 단계적으로 구축
- 스트리밍 ETL에 필요한 핵심 알고리즘(Reservoir Sampling, Bloom Filter, Sliding Window & Watermark, HLL, CDF/Cutoff, Pareto Front)을 실무 친화적으로 적용
- 실습자료_2024의 기술스택(PySpark/Spark SQL, Pandas, Streamlit, YouTube API v3)을 준수하면서, 제한 환경에 대비한 폴백 경로(Pandas/CSV)를 병행
- 결과를 재현 가능한 코드·로그·아티팩트로 남기고, 대시보드(UI)에서 최신 분포 맥락(CDF/PDF)과 예측/라벨을 함께 제시

## 2. 설계/알고리즘 (선택 이유·대안 비교)

### 2.1 전체 아키텍처 개요

```
┌─────────────────────────────────────────────────────────────────┐
│                    소셜 비디오 빅데이터 실시간 처리 플랫폼                │
└─────────────────────────────────────────────────────────────────┘

┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│   Sources   │    │   Ingest    │    │   Bronze    │    │   Silver    │
├─────────────┤    ├─────────────┤    ├─────────────┤    ├─────────────┤
│YouTube API  │───▶│Reservoir    │───▶│Bronze Delta │───▶│Structured   │
│Social Events│    │Sampling     │    │(partitioned)│    │Streaming    │
└─────────────┘    │Bloom Filter │    └─────────────┘    │Watermark    │
                   │Landing JSON │                       │Sliding Win  │
                   └─────────────┘                       └─────────────┘
                                                              │
                                                              ▼
┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│   Gold      │    │  Modeling   │    │  Serving    │    │  Checkpoint │
├─────────────┤    ├─────────────┤    ├─────────────┤    ├─────────────┤
│HLL/approx   │◀───│LR/RF/GBT    │◀───│Streamlit    │    │chk/silver/  │
│CDF cutoff   │    │Pareto Front │    │UI           │    │             │
│Gold Features│    │Artifacts    │    │Predictions  │    │             │
└─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘
```

**데이터 흐름:**
1. **Sources** → **Ingest**: YouTube API와 소셜 이벤트 데이터 수집
2. **Ingest** → **Bronze**: Reservoir Sampling과 Bloom Filter를 통한 중복 제거  
3. **Bronze** → **Silver**: Structured Streaming과 Watermark를 통한 실시간 처리
4. **Silver** → **Gold**: HLL과 CDF를 통한 피처 엔지니어링
5. **Gold** → **Modeling**: 다중 모델 학습 및 Pareto Front 최적화
6. **Modeling** → **Serving**: Streamlit UI를 통한 결과 제공

### 2.2 핵심 알고리즘 및 선택 근거
- Reservoir Sampling (Vitter’s Algorithm R)
  - 선택 이유: 스트림 상 샘플 대표성 유지(O(k) 메모리), 폭증 구간 사전 점검/프로파일링에 적합
  - 대안: 전수 샘플링(비현실적), 시스템 샘플링(분포 편향), 오프라인 무작위 추출(지연/메모리 부담)
- Bloom Filter
  - 선택 이유: 최근 n일 ID에 대한 멤버십 빠른 판정(False Positive 허용, False Negative 없음), 저장/조인 비용 절감
  - 대안: 해시셋(메모리 비효율), 트리/인덱스(삽입/삭제 비용), LRU 캐시(멤버십 오탐 제어 어려움)
- Sliding Window & Watermark
  - 선택 이유: 이벤트 시간 기반 지연 허용(예: 10분)과 중복 제거 보장, 운영 상 일관된 지표 산출
  - 대안: 처리시간 처리(지연 이벤트 왜곡), 세션 윈도우(시나리오 제한)
- 근사 고유 카운트(HLL/Flajolet–Martin 계열)
  - 선택 이유: 대규모 스트림에서 고유 사용자 수를 경량 추정, Spark의 approx_count_distinct로 대체 가능
  - 대안: 정확 집계(비용 과다), 샘플 기반 추정(편향)
- CDF 기반 동적 Cut-off 라벨링
  - 선택 이유: 분포에 따라 상위 p% 라벨을 자동 결정(환경 변화 대응), 고정 임계치의 경직성을 해소
  - 대안: 수동/고정 임계(데이터 드리프트 취약), 규칙 기반 점수
- Pareto Front(다목적 최적화)
  - 선택 이유: AUC(↑), 지연(↓), 복잡도(↓) 등 상충 지표에서 지배/비지배 관계로 효율적 후보군 추출
  - 대안: 가중합(가중치 설계 난해/변동), 단일지표 극대화(운영 적합성 낮음)

## 3. 구현 (구조도/흐름·주요 코드)

### 3.1 구현 스택·경로
- 실습자료_2024 스택 준수: PySpark/Spark SQL, Pandas, YouTube API v3, Streamlit, (선택) MLflow
- 실행 경로(루트 기준)
  - 00 Scaffold: `python scripts/scaffold_project.py`
  - 01 Fetch: `python -m video_social_rtp.cli fetch --max-items 50 --query "K-POP" --relevance-language ko --region-code KR --skip-if-exists`
  - 01 Bronze: `python -m video_social_rtp.cli bronze`
  - 02 Silver: `python -m video_social_rtp.cli silver --once`
  - 03 Gold: `python -m video_social_rtp.cli gold --top-pct 0.9`
  - 04 Train: `python -m video_social_rtp.cli train`
  - 05 UI: `python -m video_social_rtp.cli ui`
- 런타임 경로: `.env`의 `PROJECT_ROOT=project` 하위에 `data/landing|bronze|silver|gold`, `chk`, `logs`, `artifacts`

### 3.2 단계별 구현 요점
- 01 수집(ingest/youtube.py)
  - YouTube Data API v3 `search.list`로 최대 50건/호출 수집
  - 지역/언어 파라미터 지원, 오류/부분응답 파싱 보강, fields 축소로 트래픽 절감
  - Reservoir 샘플 JSON 별도 저장(프로파일링/디버깅)
  - 동일 키워드/당일 중복호출 방지 마커 작성(`landing/_markers/*.json`)
- 01 배치(bronze/batch.py)
  - Spark+Delta 적재(파티션: `ingest_date`, `source`), 최근 Bronze로 Bloom 필터 생성 후 중복 차단
  - 환경 제약 시 폴백: Landing NDJSON → `bronze/raw/*.json` 복사 및 카운트
- 02 스트리밍(silver/stream.py)
  - Structured Streaming + Watermark(10분) + Sliding Window(1시간/5분) + 중복 제거
  - `--once` 트리거 옵션으로 1회 마이크로배치 실행 지원
  - 폴백: 최근 윈도우 구간 필터링 + 영상별 카운트 CSV 산출
- 03 피처/라벨(features/gold.py)
  - Silver Delta에서 engagement_24h 집계 + HLL 근사(approx_count_distinct)
  - CDF 컷오프(상위 p%) 계산 후 라벨 부여, Delta 저장(비어 있음 대비 가드)
  - 폴백: Silver CSV → Pandas 집계/quantile → features.csv 저장
- 04 학습/선정(train/pareto.py)
  - Spark 경로: LR/RF/GBT 후보 학습(AUC-PR/지연/피처수) → Pareto Front 산출
  - MLflow(file://) 로깅(설치 환경만 활성), 폴백: Pandas 기반 단순 점수 조합 + AUC-PR 계산
- 05 UI(serve/ui.py)
  - Streamlit 대시보드: video_id 입력에 대해 최근 Silver Top-K, 존재 가능성, Gold CDF/PDF, 컷오프, 라벨 표시
  - Delta/CSV 모두 수용(Pandas 로딩 우선)

### 3.3 데이터 흐름(요약)
1) fetch: YouTube 검색 결과→NDJSON(landing) + 샘플 JSON
2) bronze: 중복 사전 필터링→Delta append(또는 raw 복사)
3) silver: 실시간 윈도우 집계→Delta(또는 CSV)
4) gold: 피처/라벨→Delta(또는 CSV), 컷오프 아티팩트 JSON
5) train: 다모델 지표→Pareto Front JSON
6) ui: CDF/PDF & 예측/라벨 & Top-K 조회

## 4. 실험/결과 (표·그래프·재현 절차)

### 4.1 실험 환경
- Python 3.12, PySpark 3.5.1, delta-spark 3.2.0, Pandas 2.3.2, Streamlit, (선택) MLflow
- 로컬 파일 시스템 기반 Delta Lake(warehouse 폴더), 체크포인트 `project/chk`
- 실행 명령(샘플)
```
# 00
cp -n .env.example .env && make scaffold
# 01
python -m video_social_rtp.cli fetch --max-items 50 --query "K-POP" --relevance-language ko --region-code KR --skip-if-exists
python -m video_social_rtp.cli bronze
# 02
python -m video_social_rtp.cli silver --once
# 03
python -m video_social_rtp.cli gold --top-pct 0.9
# 04
python -m video_social_rtp.cli train
# 05
python -m video_social_rtp.cli ui
```

### 4.2 수집/적재 결과
- landing: `project/data/landing/events_*.json` 생성 확인(샘플 10~50건)
- bronze: Delta `_delta_log` 생성 및 파티션 적재, 폴백 시 `bronze/raw/*.json`
- Reservoir 샘플 파일: `project/data/bronze/_sample/sample_*.json`

### 4.3 스트리밍 집계 결과
- Silver Delta: `project/data/silver/social_metrics/_delta_log` + `part-*.parquet`
- 폴백 예시(CSV): `video_id,count,window_end_ts` 형식으로 최근 윈도우별 카운트
- 윈도우/워터마크의 영향: 늦게 도착한 이벤트는 허용 지연(10분) 범위 내에서 집계에 반영되고, 그 외는 무시

### 4.4 피처/라벨·컷오프
- Gold Delta(정상) 또는 `features.csv`(폴백) 생성
- 컷오프 아티팩트: `project/artifacts/gold_cutoff.json` (예: `{ "percentile": 0.9, "cutoff": 28.0 }`)
- 예시(features.csv):
```
video_id,engagement_24h,uniq_users_est,label
v0,28,28,1
v1,20,20,0
...
```
- CDF/PDF: UI에서 engagement_24h의 누적 분포와 컷오프를 시각 확인

### 4.5 학습/선정(Pareto)
- 결과 아티팩트: `project/artifacts/pareto.json`
- Spark 경로: 각 후보(LR/RF/GBT)에 대해 AUC-PR·추론지연(ms)·피처수 기록 → Pareto Front 추출
- 폴백 경로: 단순 점수 조합 3종(simple/medium/complex)으로 AUC-PR 비교 → Pareto Front
- 예시(Pareto Front 1개): simple(aucpr=1.0, latency=5ms, feat=1)

### 4.6 재현 절차 요약
1) `.env`에 `YT_API_KEY` 입력, `make scaffold` 후 01→04 순으로 CLI 실행
2) 각 단계 로그와 산출물을 `submission/스크린샷_가이드.md` 지침에 따라 캡처
3) UI 실행 후 브라우저에서 분포/컷오프/라벨 확인 및 화면 캡처

## 5. 고찰 (한계·개선안)

### 5.1 한계
- 데이터 볼륨: 로컬/학습용 볼륨에 적합한 수준으로 구성. 대규모 실데이터에서는 스토리지·메모리·네트워크 자원 고려 필요
- API 쿼터: YouTube Data API v3는 일일 쿼터(기본 10,000 units) 제한. `search.list` 100 units/호출로 설계 시 하루 100회 수준
- 지표 단순화: 실습/과제 목적상 engagement_24h를 주 지표로 구성. 실제 운영은 다차원 피처/라벨 정교화 필요
- 폴백 경로: 제한 환경에서도 동작하도록 CSV/Pandas 경로 제공. 하지만 운영 환경은 Delta/Spark 경로를 권장
- MLflow/서빙: 로컬 파일 기반 MLflow만 시험. 모델 서빙/배포 파이프라인은 범위 외

### 5.2 개선안
- 수집 고도화: `videos.list`(배치로 id 묶음 조회), 키워드 클러스터링, 주기적 증분 수집 + 변경 데이터 캡처(CDC)
- 중복 제거 강화: Bloom 필터 파라미터 튜닝(k, fpp), 최근 n일 슬라이딩 윈도우별 복수 필터 병행
- 스트리밍 안정화: 상태 저장·재시작·옵셋 관리 강화, 모니터링(Prometheus)·경보 체계 도입
- 피처 엔지니어링: 텍스트 임베딩(TF-IDF/BERT), 시계열 특성(증감률/지연), 사용자·영상 조인 피처 확대
- 모델 선택: 샘플 효율적 학습(Hyperopt/Optuna + Pareto), 드리프트 탐지 및 재학습 자동화
- UI/서빙: 캐시/쿼리 최적화, 검색/필터·다운로드 기능 추가, 인증/권한관리

## 6. 참고문헌·라이선스
- YouTube Data API v3, https://developers.google.com/youtube/v3
- Apache Spark 3.5.1, https://spark.apache.org/
- Delta Lake / delta-spark 3.2.0, https://delta.io/
- Vitter, J. S. (1985). Random Sampling with a Reservoir. ACM TOMS.
- Bloom, B. H. (1970). Space/Time Trade-offs in Hash Coding with Allowable Errors. CACM.
- Flajolet, P., Martin, G. N. (1985). Probabilistic Counting Algorithms for Data Base Applications. JCSS.
- Pareto Optimality (다목적 최적화) 개론, 다수의 교과서/정리 문서
- Pandas, Streamlit, MLflow 공식 문서
- 라이선스: 본 프로젝트 저장소는 Apache-2.0(루트 `LICENSE`)을 따른다. 외부 라이브러리는 각 라이선스를 준수한다.

## 부록 A. AI 활용 내역

### A.1 AI 도구 사용 현황
본 과제 수행 과정에서 다음과 같은 AI 도구를 활용하였습니다:

#### A.1.1 코드 생성 및 구현
- 도구: **OpenAI Codex CLI (GPT-5 모델)**
- 활용 범위: 
  - PySpark 스트리밍 처리 코드 작성
  - YouTube API v3 연동 코드 구현
  - Delta Lake 파이프라인 구성
  - Streamlit 대시보드 UI 개발
- 사용 내역: 전체 코드의 약 70%가 Codex CLI의 GPT-5 모델을 통해 생성되었으며, 모든 코드는 작성자가 검토 및 수정하여 최종 구현

#### A.1.2 프로젝트 설계 및 아키텍처
- 도구: **Claude Sonnet 4**
- 활용 범위:
  - 전체 시스템 아키텍처 설계
  - 데이터 파이프라인 구조 설계
  - 알고리즘 선택 및 비교 분석
  - 보고서 구조 및 내용 구성
- 사용 내역: 프로젝트 초기 설계 단계에서 아이디어 보조 및 구조화에 활용

#### A.1.3 프로젝트 셋업 및 환경 구성
- 도구: **Cursor IDE**
- 활용 범위:
  - 프로젝트 초기 구조 설정
  - 개발 환경 구성 및 의존성 관리
  - 파일 구조 및 디렉토리 구성
  - 개발 워크플로우 설정
- 사용 내역: 프로젝트 초기 셋업 단계에서 개발 환경 구성 및 프로젝트 구조 설정에 활용

### A.2 AI 활용 원칙 및 검증
- 원칙: AI는 아이디어 보조 및 코드 생성 보조 목적으로만 활용
- 검증: 모든 AI 생성 코드는 작성자가 직접 검토, 테스트, 수정하여 최종 구현
- 투명성: 본 부록을 통해 AI 활용 내역을 명시적으로 공개

---
