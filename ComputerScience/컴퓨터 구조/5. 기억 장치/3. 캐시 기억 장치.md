
---
### 3. ==캐시 기억 장치==
- **캐시의 사용 목적**
  - ==CPU와 주기억 장치의 속도 차이로 인한 CPU 대기 시간을 최소화 시키기 위하여== CPU와 주기억 장치 사이에 설치하는 ==고속 반도체 기억장치(SRAM)==
- **캐시의 특징**
  - 주기억 장치보다 액세스 속도가 높은 칩 사용
  - 가격 및 제한된 공간 때문에 용량이 적다.
- **책상 위(레지스터), 서랍(캐시), 파일 캐비닛(주기억 장치)의 비교**
  ![](../../../../image/Pasted%20image%2020240530102042.png)
- **캐시의 기본적인 동작 흐름도**
  - CPU가 기억 장치에서 어떤 정보(명령어 또는 데이터)를 읽으려는 경우 ==먼저 해당 정보가 캐시에 있는지 검사==한다.
  - 있다면 해당 정보를 즉시 읽어 들이고, ==없다면 해당 정보를 주기억 장치에서 캐시로 적재==한 후 읽어 들인다.
  ![](../../../../image/Pasted%20image%2020240530102200.png)
- **캐시의 히트율 및 평균 액세스 시간**
  - ==캐시 히트(cache hit)== : CPU가 원하는 데이터가 캐시에 있는 상태
  - ==캐시 미스(cache miss)== : CPU가 원하는 데이터가 캐시에 없는 상태, 이 경우에는 주기억 장치로부터 데이터를 읽어온다.
  - ==히트율(hit ratio)== : 캐시에 히트되는 정도 $(H)$
    ![](../../../../image/Pasted%20image%2020240530102348.png)
  - ==캐시의 미스율(miss ratio)== = $(1 - H)$
  - 평균 기억장치 액세스 시간 $(T_a)$
    ![](../../../../image/Pasted%20image%2020240530102440.png)
  ![](../../../../image/Pasted%20image%2020240530103640.png)
  ![](../../../../image/Pasted%20image%2020240530103712.png)
- **참조 ==지역성==(locality of reference)**
  - ==공간적 지역성==(spatial locality) : 기억장치 내에 인접하여 저장되어 있는 데이터들이 연속적으로 액세스될 가능성이 높다. 예를 들어 표나 배열의 데이터들이 저장되어 있는 기억 장치 영역은 관련 연산이 수행되는 동안 자주 액세스된다.
  - ==시간적 지역성==(temporal locality) : 최근에 액세스된 프로그램이나 데이터가 가까운 미래에 다시 액세스될 가능성이 높다. 예를 들어 서브루틴이나 루프 프로그램들은 반복적으로 호출되며, 공통 변수들도 자주 액세스된다.
  ![](../../../../image/Pasted%20image%2020240530104050.png)
  - ==전형적인 많은 프로그램을 분석해보면 그림처럼 주어진 시간 동안에 메모리 참조는 한정된 영역에서만 이루어지는 경향이 있음. 이러한 현상을 참조 지역성==
  - 예) 도서관에서 캐시에 대한 내용을 찾기 위해 컴퓨터 구조 책을 찾아왔다면 그 책 주위에 이와 유사한 책이 많다(==공간적 지역성==) 또 그 책을 책상으로 가지고 왔다면 머지않아 그 책을 다시 찾아볼 가능성이 매우 크다(==시간적 지역성==)
- **캐시 설계에 있어서의 공통적인 목표**
  - ==캐시의 히트율을 극대화해야 한다.==
  - 캐시 히트인 경우 캐시에서 정보를 읽어 오는 ==시간을 최소화해야 한다.==
  - 캐시 미스인 경우 주기억 장치에서 캐시로 정보를 가져오는 데 걸리는 ==시간을 최소화해야 한다.==
  - 캐시의 내용이 변경되었을 경우 주기억 장치에 해당 내용을 갱신하는 데 소요되는 시간을 최소화해야 한다.
- **캐시 설계의 설계 요소**
  ![](../../../../image/Pasted%20image%2020240530104503.png)
  ##### 1. 캐시 용량
  - 캐시 메모리 용량이 커질수록 히트율은 높아지지만, 비용이 증가
  - 용량이 커질수록 주소 해독 및 정보 인출을 위한 주변 회로가 복잡해지므로 액세스 시간이 다소 더 길어진다.
  - CPU 칩 또는 메인보드의 공간에도 제한을 받는다.
  ##### 2. ==사상 방식==
  - ==블록(block)== : 주기억 장치와 캐시 사이에 이동되는 정보 단위
  - 주기억 장치 용량 = $2^{n}$ 워드, 블록 = $K$개 워드 -> ==블록의 수== = $2^{n}/K$개 
  - ==라인(line)== : 캐시에서 각 블록이 저장되는 장소, 라인 수 $m$개, 각 라인에는 워드 $K$개가 저장된다.
  - ==태그(tag)== : 라인에 적재된 블록을 구분해주는 정보
  - 주기억 장치의 ==블록== 중에서 일부만이 ==캐시에 적재될 수 있으므로 캐시의 각 라인은 여러 블록이 공유한다.==
  ![](../../../../image/Pasted%20image%2020240530104856.png)

##### 1. 캐시 용량
- 캐시 메모리 용량이 커질수록 히트율은 높아지지만, 비용이 증가
- 용량이 커질수록 주소 해독 및 정보 인출을 위한 주변 회로가 복잡해지므로 액세스 시간이 다소 더 길어진다.
- CPU 칩 또는 메인보드의 공간에도 제한을 받는다.
##### 2. ==사상 방식==
- ==블록(block)== : 주기억 장치와 캐시 사이에 이동되는 정보 단위
- 주기억 장치 용량 = $2^{n}$ 워드, 블록 = $K$개 워드 -> ==블록의 수== = $2^{n}/K$개 
- ==라인(line)== : 캐시에서 각 블록이 저장되는 장소, 라인 수 $m$개, 각 라인에는 워드 $K$개가 저장된다.
- ==태그(tag)== : 라인에 적재된 블록을 구분해주는 정보
- 주기억 장치의 ==블록== 중에서 일부만이 ==캐시에 적재될 수 있으므로 캐시의 각 라인은 여러 블록이 공유한다.==
	![](../../../../image/Pasted%20image%2020240530104856.png)
- ==사상 방식(mapping scheme)==
	- 사상 방식이란 ==주기억 장치의 블록이 어느 캐시 라인에 들어갈 것인지 결정하는 방법==
		- 직접 사상(direct mapping)
		- 완전-연관 사상(fully-associative mapping)
		- 세트-연관 사상(set-associative mapping)
- 사상 방식을 설명하기 위한 모델 예
	- 주기억 장치의 용량은 128바이트, 캐시 용량은 32바이트
	- 주기억 장치 주소 = 7비트 (바이트 단위로 주소가 지정, 워드 길이는 1바이트)
	- ==블록 크기 = 4바이트 -> 주기억 장치에는 128/4 = 32개의 블록이 있다.==
	- ==캐시 라인의 크기 = 4바이트(블록 크기와 동일)==
	- ==전체 캐시 라인의 수 , m= 32/4 = 8개==
		![](../../../../image/Pasted%20image%2020240612152339.png)]
- ==직접 사상 (direct mapping)==
	- 주기억 장치의 블록들이 ==지정된 하나의 캐시 라인으로만 적재됨==
	- 주기억 장치 주소는 필드 3개로 구성된다. 주기억 장치의 주소 지정에는 7비트가 필요하므로 t + s + w = 7이다.
	- 한 블록 내에는 워드 4개가 들어가므로 각 워드를 구별하기 위해 w=2비트가 필요하다
	- 캐시 라인의 수가 8개이므로 각각을 구별하기 위해 s = 3비트
	- 그리고 태그 필드는 나머지 t=2(=7-3-2)비트가 된다.
	- ==태그 필드 값은 캐시 라인을 공유하는 주기억 장치 블록들을 서로 구분하는 데 사용된다.==
		![](../../../../image/Pasted%20image%2020240530111021.png)
	- 주기억 장치의 블록 j(=0, 1, …, 31)가 적재될 수 있는 캐시 라인 번호는 다음 연산으로 결정된다. (mod : ==나머지 연산자==)$$i = j\mod\ m$$
	- ==예) 캐시라인수 m=8, 주기억 장치 10번째 블록 j=10인 경우, 10 mod 8 = 2이므로 2번째 캐시 라인에 들어감==
	- \[표 6-7]에는 각 캐시 라인을 공유하는 블록들의 번호 4(=$2^{t}$=$2^{2}$)개가 나열되어 있다. 여기서 블록 번호는 주기억 장치 주소의 상위 5비트에 해당한다.
	![](../../../../image/Pasted%20image%2020240530111404.png)
	![](../../../../image/Pasted%20image%2020240530111434.png)
	- 직접 사상에서 캐시 내부 구성 및 읽기 동작 
		➊ 캐시로 ==주기억 장치 주소 11 101 01==이 보내진다(태그 필드=11, 라인 필드=101, 워드 필드=01).
		➋ 라인 필드가 101이므로 5번 캐시 라인이 선택된다.
		➌ 선택된 5번 라인의 태그 비트 11을 읽어서,
		➍ 주기억 장치 주소의 태그 필드인 11과 비교한다.
		➎ ==두 태그 비트가 일치하므로 캐시가 히트된 것이다.==
		➏ 다음에는 주소의 워드 필드가 01이므로 poet 중에서 o(1110 1111)가 인출되어 CPU로 전송된다.
		➐ 그러나 태그 비트가 일치하지 않으면 캐시가 미스된 것이므로 ==주소 전체가 주기억 장치로 보내져서 해당 블록을 인출해 온다.== 인출된 블록은 지정된 캐시 라인에 저장된다. 그런데 그 라인을 공유하는 ==다른 블록이 이미 저장되어 있는 상태라면 원래 블록은 지워지고 새로 인출된 블록이 저장된다==
		![](../../../../image/Pasted%20image%2020240530111633.png))
![](../../../../image/Pasted%20image%2020240530111728.png)
- 직접 사상 캐시의 장단점
	- 장점 : ==하드웨어가 간단하고, 구현 비용이 적게 든다.==
	- ==단점== : 각 주기억 장치 블록이 적재될 수 있는 캐시 라인이 한 개 뿐이기 때문에, ==그 라인을 공유하는 다른 블록이 적재되는 경우에는 반복적으로 미스되어 히트율이 떨어짐 (swap-out)==
- ==완전-연관 사상(fully-associative mapping)==
	- ==주기억 장치 블록이 캐시의 어떤 라인으로든 적재 가능==
	- 태그 필드 = 주기억 장치 블록 번호
		![](../../../../image/Pasted%20image%2020240530112001.png)
	- 각 캐시 라인의 태그에는 주소의 워드 필드(2비트)를 제외한 상위 5비트가 저장되어 주기억 장치의 어느 블록이 저장되었는지 나타낸다.
	- 캐시의 라인 번호와 그 태그 필드는 관련이 없다.
	![](../../../../image/Pasted%20image%2020240530112128.png)!![](../../../../image/Pasted%20image%2020240530112152.png)
- 완전-연관 사상에서 캐시 내부 구성 및 읽기 동작 
	➊ 캐시로 주기억 장치 주소 11001 11이 보내진다. 태그 필드는 11001이고, 워드 필드는 11이다. 
	➋ 캐시의 모든 라인의 태그들과 주기억 장치 주소의 태그 필드 내용을 비교한다. 
	➌ 2번 캐시 라인의 11001과 주소의 태그 필드 11001이 일치하므로 ==캐시가 히트된 것이다.== 
	➍ 다음에는 주소의 워드 필드가 11이므로 navy 중에서 y(0111 1001)가 인출되어 CPU로 전송된다. 
	➎ 만약, 태그 비트가 일치하지 않는 경우, 캐시가 미스된 것이므로 주소 전체가 주기억 장치로 보내져서 해당 블록을 인출해 온다. 인출된 블록은 5번 캐시 라인에 저장된다
	
	![](../../../../image/Pasted%20image%2020240530112315.png)
![](../../../../image/Pasted%20image%2020240530112357.png)
-  세트-연관 사상(set-associative mapping) 
	- 직접 사상의 장점(==단순성==)과 완전-연관 사상의 장점(==높은 캐시 히트율==) 조합 
	- 주기억 장치 블록 그룹이 하나의 캐시 세트를 공유하며, 그 세트는 두 개 이상의 라인들에 적재될 수 있음 
	- 전체 캐시 라인(m)은 v개의 세트들로 나누어지며, 각 세트들은 k개의 라인들로 구성(==k-way==) 
	- 주기억 장치 블록(j)이 적재될 수 있는 캐시 세트의 번호 i : 
		- ![](../../../../image/Pasted%20image%2020240530112533.png)
	- 앞의 예에서 캐시 라인의 수는 m=8이다. 세트당 캐시 라인의 수가 k=2라면 세트 수는 ==v=8/2=4개다.== 따라서 캐시는 세트 4개로 구성되고, 각 세트에 캐시 라인이 2개 있다.
	- 주기억 장치의 블록 j(=0, 1, …, 31)가 적재될 수 있는 세트 번호는 j mod 4로 결정된다. 
	- 세트-연관 사상 방식에서 세트 4개, 세트당 캐시 라인 2개에 들어갈 수 있는 주기억 장치 블록 32개는 다음과 같다.
	![](../../../../image/Pasted%20image%2020240530112750.png)
![](../../../../image/Pasted%20image%2020240530112824.png)
- 세트-연관 사상에서 캐시 내부 구성 및 읽기 동작 
	➊ 주기억 장치 주소 ==001 00 10==이 캐시로 보내진다(태그 필드=001, 세트 필드=00, 워드 필드= 10). 
	➋ 00 세트 번호를 이용해 캐시의 0번 세트를 선택한다. 
	➌ 0 번 세트 라인의 태그에 주기억 장치 주소의 태그 비트 001과 일치하는 것이 있는지 검사한다. 
	➍ 0번 세트 내 첫 번째 라인의 태그 비트가 ==001이므로 히트되었다.==
	➎ 다음에는 주소의 워드 필드가 10이므로 gift 중에서 f(1110 0110)가 인출되어 CPU로 전송된다. 
	➏ 만약, 태그 비트가 일치하지 않으면 캐시가 미스된 것이므로 주소 전체가 주기억 장치로 보내져서 해당 블록을 인출해 온다. 적절한 교체 알고리즘에 의하여 2개 중 하나를 선택하여 그 라인에 새로운 블록을 적재해야 한다.
		![](../../../../image/Pasted%20image%2020240530112940.png)
![](../../../../image/Pasted%20image%2020240530113029.png)
- 사상 방식의 비교
	![](../../../../image/Pasted%20image%2020240530113212.png)
##### ==3. 교체 알고리즘 (시험 예상)==
- 세트-연관 사상에서 주기억 장치로부터 새로운 블록이 캐시로 적재될 때, 만약 세트 내 모든 라인들이 다른 블록들로 채워져 있다면, ==그들 중의 하나를 선택하여 새로운 블록으로 교체==
- 교체 알고리즘 : ==캐시 히트율을 극대화할 수 있도록 교체할 블록을 선택하기 위한 알고리즘==
	- ==LRU==(Least Recently Used) : 사용되지 않은 채로 가장 오래 있었던 블록을 교체하는 방식 
	- ==FIFO==(First-In-First-Out) 알고리즘 : 캐시에 적재된 지 가장 오래된 블록을 교체하는 방식 
	- ==LFU==(Least Frequently Used) 알고리즘 : 참조되었던 횟수가 가장 적은 블록을 교체하는 방식 
	- ==Random== : 사용 횟수를 고려하지 않고 후보 캐시 라인 중 임의로 선택하여 교체하는 방식
	![](../../../../image/Pasted%20image%2020240530113350.png)
![](../../../../image/Pasted%20image%2020240530113435.png)
![](../../../../image/Pasted%20image%2020240530113457.png)
##### ==4. 쓰기 정책 write plicy (시험 예상)==
- 캐시의 블록이 변경되었을 때 그 내용을 주기억 장치에 갱신하는 시기와 방법의 결정
- ==Write-through (캐시 일관성 o)==
	- 모든 쓰기 동작들이 캐시로 뿐만 아니라 주기억 장치로도 동시에 수행되는 방식 
- ==Write-back (캐시 일관성 x )==
	- 캐시에서 데이터가 변경되어도 주기억 장치에는 갱신되지 않는 방식
	![](../../../../image/Pasted%20image%2020240530113650.png)
- ==각 방식의 장단점==
	- Write-through
		- 장점 : 캐시에 적재된 블록의 내용과 주기억 장치에 있는 그 블록의 내용이 항상 같다.
		- 단점 : 모든 쓰기 동작이 주기억 장치 쓰기를 포함하므로, ==쓰기 시간이 길어진다.==
	- Write-back
		- 장점 : 기억장치에 대한 쓰기 동작의 횟수가 최소화되고, ==쓰기 시간이 짧아진다.==
		- 단점 : ==캐시의 내용과 주기억 장치의 해당 내용이 서로 다르다(캐시 일관성).==
	- 캐시 일관성 (Cache Coherence)
		- 블록을 교체할 때는 캐시의 상태를 확인하여 주기억 장치에 갱신하는 동작이 선행되어야 하며, 그를 위하여 각 캐시 라인이 상태 비트(status bit)를 가지고 있어야 한다. 

![](../../../../image/Pasted%20image%2020240530114201.png)

##### 5. 라인 크기
- 블록 크기에 따른 특성
	- 캐시 용량은 한정되어 있기 때문에 블록 크기가 커질수록 캐시에 들어올 수 있는 블록의 수는 줄어든다. 새로운 블록을 읽어 올 때마다 원래 캐시 내용은 교체되기 때문에 블록 수가 적으면 인출된 직후에 다른 블록과 다시 교체된다.
	- ==블록 크기가 커질수록 원하는 워드에서 멀리 떨어져 있는 워드들도 같이 읽혀 오며, 그들은 가까운 미래에 사용될 가능성은 낮다.==
	- 대략적으로 ==블록 크기가 8~32바이트 정도가 최적에 가까운 것으로 알려져 있다.==

##### 6. 캐시 수
- 계층적 캐시
	- 온-칩 캐시(on-chip cache) : 캐시 액세스 시간을 단축시키기 위하여 CPU 칩 내에 포함시킨 캐시(그림의 L1)
	- 계층적 캐시(hierarchical cache) : 온-칩 캐시를 1차(L1) 캐시로 사용하고, CPU 외부에 더 큰 용량의 2차(L2) 캐시를 설치하는 방식 
	- 분리 캐시(split cache) : 캐시를 명령어 캐시와 데이터 캐시로 분리
	![](../../../../image/Pasted%20image%2020240530114545.png)
- 계층적 캐시에서의 히트율 
	- L2의 용량이 L1보다 크며, L1의 모든 내용이 L2에도 존재 
	- 먼저 L1을 검사하고, 만약 원하는 정보가 L1에 없다면 L2를 검사하며, L2에도 없는 경우에는 주기억 장치를 액세스 
	- L1은 속도가 빠르지만, 용량이 작기 때문에 L2 보다 히트율은 더 낮다. 
	- ==평균 기억 장치 액세스 시간(Ta)==
		![](../../../../image/Pasted%20image%2020240530114656.png)
![](../../../../image/Pasted%20image%2020240530114724.png)
- 통합 캐시와 분리 캐시 
	- 통합 캐시(unified cache) 
		- 온-칩 캐시가 처음 출현했을 때, 대부분은 명령어와 데이터를 하나의 캐시에 저장 
	- 분리 캐시(split cache) 
		- 캐시를 명령어 캐시와 데이터 캐시로 분리 
		- 명령어 인출 유니트와 실행 유니트 간의 캐시 액세스 충돌 제거 
		- 고성능 파이프 라인 프로세서들에서 사용