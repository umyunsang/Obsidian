
---
## **STFT와 함께 추가할 수 있는 Feature 후보**
### **1. 주파수 대역별 에너지 분포 (Mel Spectrogram)**
- STFT는 선형 주파수 축을 가지지만, 인간의 청각은 로그 스케일(멜 스케일)로 소리를 인식함.
- 따라서 **Mel Spectrogram을 추가 입력으로 활용**하면 신경망이 음향 데이터를 더 풍부하게 학습할 수 있음.

**추가 이유**  
- **STFT와 동일한 형태의 2D Tensor 데이터** (Frequencies × Time)  
- **STFT보다 더 압축된 표현**을 제공하여 노이즈에 강한 특징을 학습 가능  
- 기존 STFT와 함께 모델에 입력하면 성능 개선 가능  

**PyTorch 코드 추가 예시**
```python
def audio2mel(raw_audio, sr=16000, n_fft=128, hop_length=256, n_mels=64):
    mel_spec = librosa.feature.melspectrogram(
        y=raw_audio,
        sr=sr,
        n_fft=n_fft,
        hop_length=hop_length,
        n_mels=n_mels
    )
    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)
    mel_spec_db = (mel_spec_db - np.min(mel_spec_db)) / (np.max(mel_spec_db) - np.min(mel_spec_db))
    return mel_spec_db
```
-> **STFT와 같은 차원(Frequencies × Time)으로 모델에 입력 가능**  

---

### **2. 임베딩 벡터 기반 특징 (Wav2Vec, HuBERT, MFCC)**
- 최근 **딥러닝 기반 오디오 임베딩 모델**은 원본 오디오에서 의미 있는 feature를 추출하는 데 강력함.
- 따라서 **STFT와 함께 사용하면 성능이 향상될 가능성이 큼**.

**추가 이유**  
- Wav2Vec, HuBERT: **Transformer 기반 오디오 임베딩**으로 신경망이 강건한 표현 학습 가능  
- MFCC (Mel-Frequency Cepstral Coefficients): 오디오 데이터를 **2D 스펙트럼 형태로 변환 가능**  
- **STFT와 함께 넣으면 모델이 더 일반화된 특징을 학습**할 수 있음  

**PyTorch 코드 추가 예시 (MFCC)**
```python
def audio2mfcc(raw_audio, sr=16000, n_mfcc=13):
    mfcc_features = librosa.feature.mfcc(y=raw_audio, sr=sr, n_mfcc=n_mfcc)
    mfcc_features = (mfcc_features - np.min(mfcc_features)) / (np.max(mfcc_features) - np.min(mfcc_features))
    return mfcc_features
```
-> **STFT와 동일한 형태의 2D Tensor로 변환 가능**  

---

### **3. 주파수 중심값 (Spectral Centroid)**
- **주파수의 "무게 중심"을 나타내는 특징**으로, 오디오 신호의 에너지가 어느 주파수 대역에 집중되어 있는지 나타냄.  
- 음향적 특징을 보완하는 역할을 하며 **STFT와 함께 입력하면 모델이 주파수 대역을 더 효과적으로 분석할 수 있음**.  

**추가 이유**  
- **STFT와 같은 시계열 패턴을 가지므로 CNN/RNN 기반 모델에 입력 가능**  
- 특정 소리가 높은 주파수인지, 낮은 주파수인지 학습 가능  
- 추가적으로 spectral bandwidth, roll-off 등을 함께 사용할 수 있음  

**PyTorch 코드 추가 예시**
```python
def audio2spectral_centroid(raw_audio, sr=16000, n_fft=128, hop_length=256):
    spectral_centroid = librosa.feature.spectral_centroid(y=raw_audio, sr=sr, n_fft=n_fft, hop_length=hop_length)
    spectral_centroid = (spectral_centroid - np.min(spectral_centroid)) / (np.max(spectral_centroid) - np.min(spectral_centroid))
    return spectral_centroid
```
-> **1D feature라면 채널을 확장하여 2D 형태로 변환 후 모델에 입력 가능**  

---

## **STFT 없이 동일한 형태의 입력을 전달하려면?**
STFT가 없을 때 **동일한 차원의 2D Tensor를 모델에 입력하려면**, 아래 방법을 고려할 수 있음.

### **Mel Spectrogram + MFCC 조합**
- **STFT 대신 Mel Spectrogram을 사용**하고, 추가적으로 **MFCC를 사용하여 특징을 강화**  
- 둘 다 **(Frequency × Time) 형태로 변환할 수 있어 STFT와 동일한 차원 유지 가능**  

**2D 형태로 바로 CNN, Transformer 등에 입력 가능**  
```python
mel_spec = audio2mel(raw_audio)
mfcc = audio2mfcc(raw_audio)

# 같은 차원으로 맞추기 위해 interpolation 적용 가능
mfcc_resized = librosa.util.fix_length(mfcc, size=mel_spec.shape[1], axis=1)

# STFT 대신 Mel Spectrogram과 MFCC를 concatenate하여 입력
combined_features = np.concatenate((mel_spec, mfcc_resized), axis=0)
```
---

### **Wav2Vec / HuBERT 임베딩 (딥러닝 기반 특징 추출)**
- **Transformer 기반 오디오 임베딩 모델을 사용하면**, STFT 없이도 **고수준의 feature를 직접 추출 가능**.  
- **STFT가 없어도 CNN, Transformer 모델에 바로 입력할 수 있는 형태로 변환 가능**  

**Pretrained 모델 사용 예시**
```python
import torchaudio
import torchaudio.transforms as T
from transformers import Wav2Vec2Processor, Wav2Vec2Model

# Wav2Vec2 모델 로드
processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base")
model = Wav2Vec2Model.from_pretrained("facebook/wav2vec2-base")

# 오디오 불러오기
waveform, sample_rate = torchaudio.load("example.wav")

# Wav2Vec2 모델을 통해 feature 추출
inputs = processor(waveform, sampling_rate=sample_rate, return_tensors="pt")
with torch.no_grad():
    embeddings = model(**inputs).last_hidden_state  # (Batch, Time, Features)

# CNN이나 Transformer 모델에 바로 입력 가능
```
-> **STFT 없이 바로 딥러닝 모델에서 사용할 수 있음**  

---

## **결론: 딥러닝 관점에서 최적의 입력 조합**
| Feature                   | 설명                          | STFT가 없을 때 대체 가능 여부 |
| ------------------------- | --------------------------- | ------------------- |
| **Mel Spectrogram**       | STFT보다 더 인간 청각에 적합한 변환      | 가능                  |
| **MFCC**                  | 주파수 특성을 더 압축해서 제공           | 가능                  |
| **Wav2Vec2 / HuBERT 임베딩** | Pretrained 모델 활용, 고수준 특징 학습 | 가능                  |
| **Spectral Centroid**     | 주파수 중심값으로 소리 특성 분석          | 보완적 사용 가능           |

✅ **STFT와 함께 사용하기 좋은 조합:**  
**(STFT + Mel Spectrogram + MFCC + Spectral Features)**  
✅ **STFT 없이도 모델 입력으로 사용 가능한 대체:**  
**(Mel Spectrogram + MFCC + Wav2Vec 임베딩)**  

---

## **추천하는 추가 Feature**
1. **Mel Spectrogram**: STFT와 함께 넣을 경우 효과적  
2. **MFCC**: 오디오의 고수준 특징을 잘 압축함  
3. **Spectral Centroid**: 주파수 특성 분석  
4. **Wav2Vec / HuBERT 임베딩**: STFT 없이도 강력한 특징 학습 가능  

