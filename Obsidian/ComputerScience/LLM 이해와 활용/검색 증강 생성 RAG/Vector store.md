
---
### Vector Store (VectorDB)

- **Vector Store**는 데이터를 임베딩(벡터 표현)으로 저장하여 벡터 공간 내에서 빠른 검색을 구현하기 위한 데이터베이스입니다.
- **임베딩 벡터**는 텍스트, 이미지, 소리 등 다양한 형태의 데이터를 벡터 공간에 매핑한 것으로, 데이터의 의미적, 시각적, 오디오적 특성을 수치적으로 표현합니다.
- **유사도 측정 방법**: 코사인 유사도, 유클리드 거리, 맨해튼 거리 등 다양한 유사도 측정 방법을 제공합니다.

#### 벡터 스토어 패키지:

- **Faiss**: Facebook AI Research에서 개발한 오픈소스 라이브러리로, 대규모 데이터셋에서 효율적인 유사도 검색을 지원 ([Faiss GitHub](https://github.com/facebookresearch/faiss))
- **Qdrant**: 비동기 작업을 지원하는 벡터 데이터베이스 ([Qdrant](https://qdrant.tech/))
- **Chroma**: 오픈소스 벡터 데이터베이스로, 로컬 환경에서 쉽게 사용할 수 있음 ([Chroma Docs](https://docs.trychroma.com/))
- **Milvus**: 벡터 데이터베이스로, 고차원 데이터의 효율적 저장과 검색을 제공 ([Milvus](https://milvus.io/))

#### 클라우드 서비스:

- **Pinecone**: 클라우드 기반 벡터 데이터베이스 서비스로, 대규모 데이터 처리에 적합 ([Pinecone](https://www.pinecone.io/))
- **Weaviate**: 클라우드 기반 벡터 데이터베이스 서비스 ([Weaviate](https://weaviate.io/))

---

### 비정형 데이터 처리

- **비정형 데이터 처리**: 텍스트, 이미지 등 다양한 형태의 비정형 데이터를 효율적으로 저장하고 검색할 수 있습니다.
- **고차원 데이터 처리**: 수백에서 수천 차원의 고차원 벡터 데이터를 빠르게 처리할 수 있습니다.
- **유사도 기반 검색**: 벡터 간 유사도를 계산하여 가장 유사한 데이터를 빠르게 찾아낼 수 있습니다.
- **LLM 성능 향상**: 방대한 양의 정보를 효율적으로 검색하여 LLM에 제공함으로써 성능을 크게 향상시킬 수 있습니다.

---

### Vector Store - VectorDB 설명

#### Faiss

- **Faiss**는 Facebook AI Research에서 개발한 라이브러리로, 고차원 벡터 간의 유사성 검색을 빠르고 효율적으로 수행할 수 있도록 설계되었습니다.
- **지원**: CPU와 GPU 모두에서 사용 가능, 최적화된 인덱싱 구조 사용
- **용도**: 수백만 또는 수십억 개의 벡터를 처리할 수 있으며, 벡터 간의 유사성 검색을 매우 빠르게 수행합니다.
- **다양한 인덱싱 메커니즘 제공**:
    - **Flat 인덱스**: 정확한 검색을 위한 L2 거리(유클리디안 거리) 계산 (모든 벡터를 저장하고 모든 벡터와의 거리를 계산하여 가장 가까운 이웃을 찾음)
    - **IVF (Inverted File Indexing)**: 클러스터로 나누어 검색 속도를 높이고 정확도를 유지
    - **PQ (Product Quantization)**: 저장 공간을 절약하는 양자화 인덱스
- **확장성**: 단일 머신 및 클러스터 환경에서 확장 가능

---

### Vector Store 알고리즘 설명

- **IndexFlatL2**:
    
    - 유클리디안 거리(L2)를 사용하여 모든 벡터와의 거리를 계산하는 브루트포스 방식의 검색 인덱스입니다.
    - 정확도는 매우 높지만, 벡터 수가 많을 경우 계산 비용이 증가합니다.
- **IndexFlatIP**:
    
    - 내적(dot product)을 기반으로 검색을 수행하는 인덱스입니다.
    - 벡터 간의 각도 또는 방향성을 비교하는 데 유용합니다.
    - 추천 시스템이나 텍스트 임베딩에서 사용됩니다.
- **IndexIVFFlat**:
    
    - 데이터베이스를 여러 개의 클러스터로 나누고, 쿼리 벡터는 가장 가까운 클러스터를 빠르게 찾고, 그 안에서 정밀한 검색을 수행합니다.
    - 대규모 데이터셋에 대해 높은 검색 속도와 적당한 정확도를 유지할 수 있습니다.
- **IndexIVFPQ**:
    
    - **Product Quantization**을 사용하여 데이터를 더 효율적으로 저장합니다.
    - 메모리 사용량을 줄이고 빠른 검색 속도를 제공합니다.
    - 대규모 데이터셋에 적합합니다.
- **IndexLSH (Locality-Sensitive Hashing)**:
    
    - 고차원 데이터를 저차원 공간으로 해싱하여, 유사한 데이터 포인트가 같은 해시 버킷에 떨어지도록 합니다.
    - 빠른 검색 속도를 제공하지만, 정확도는 다른 방법에 비해 낮을 수 있습니다.
- **IndexHNSW (Hierarchical Navigable Small World)**:
    
    - 그래프 기반 검색 알고리즘으로, 다수의 계층에서 효율적인 경로를 통해 빠르게 근접 이웃을 찾습니다.
    - 높은 차원의 데이터에서도 우수한 검색 성능과 정확도를 제공합니다.
- **IndexPQ**:
    
    - 벡터를 여러 부분으로 나누고 각 부분을 양자화하여 저장합니다.
- **IndexSQ (Scalar Quantizer)**:
    
    - 벡터의 각 차원을 독립적으로 양자화하여 저장합니다.
    - 차원별로 양자화를 수행하여 더 세밀한 제어가 가능합니다.

---

### MMR (Maximum Marginal Relevance) 검색

- **MMR**은 유사성과 다양성의 균형을 맞추어 검색 결과의 품질을 향상시키는 알고리즘입니다.
    - **query**: 사용자로부터 입력받은 검색 쿼리
    - **k**: 최종적으로 선택할 문서의 수 (반환할 문서 개수)
    - **fetch_k**: MMR 알고리즘을 수행할 때 고려할 상위 문서의 수
    - **lambda_mult**: 쿼리와의 유사성, 선택된 문서 간의 다양성 사이의 균형을 조절 (λ=1은 유사성만 고려, λ=0은 다양성만 고려)

MMR은 **유사성**과 **다양성** 사이의 균형을 맞추어 사용자에게 더 다양한 정보를 제공합니다.