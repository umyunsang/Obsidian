
---
### Gradient Descent Method (경사 하강법)

**1. 개념:**
경사 하강법은 손실 함수의 값을 최소화하는 파라미터를 찾는 최적화 알고리즘입니다.

**2. 수식:**
경사 하강법의 갱신 과정은 다음과 같은 수식으로 나타낼 수 있습니다:
$$\theta_{t+1} = \theta_{t} - \eta \cdot \nabla J(\theta_{t})$$

여기서,
- $\theta_{t}$ : t번째 단계에서의 파라미터 값
- $\eta$  : 학습률(learning rate)
- $\nabla J(\theta_{t})$ : 손실 함수 $J(\theta)$의 기울기(gradient)
- $\theta_{t+1}$ : t+1번째 단계에서의 파라미터 값

**3. 동작 과정:**
1. 초기 파라미터 값을 설정합니다.
2. 손실 함수의 기울기(gradient)를 계산합니다: $\nabla J(\theta_{t})$.
   - 만약 기울기가 음수라면, 현재 파라미터 값에서 손실 함수의 값을 증가시키는 방향으로 이동합니다.
   - 반면에 기울기가 양수라면, 현재 파라미터 값에서 손실 함수의 값을 감소시키는 방향으로 이동합니다.
3. 현재 위치에서의 기울기에 학습률을 곱하여 이동 거리를 조절하여 파라미터를 갱신합니다.
   - 학습률은 파라미터 업데이트의 크기를 조절합니다. 너무 작으면 수렴에 시간이 오래 걸리고, 너무 크면 발산할 수 있습니다.
4. 위 과정을 반복하며 손실 함수의 값을 최소화하는 파라미터를 찾습니다.

