
---
### Gradient Descent Method (경사 하강법)

**1. 개념:**
경사 하강법은 손실 함수의 값을 최소화하는 파라미터를 찾는 최적화 알고리즘입니다.

**2. 수식:**
경사 하강법의 갱신 과정은 다음과 같은 수식으로 나타낼 수 있습니다:
$$\theta_{t+1} = \theta_{t} - \eta \cdot \nabla J(\theta_{t})$$

여기서,
- $\theta_{t}$ : t번째 단계에서의 파라미터 값
- $\eta$  : 학습률(learning rate)
- $\nabla J(\theta_{t})$ : 손실 함수 $J(\theta)$의 기울기(gradient)
- $\theta_{t+1}$ : t+1번째 단계에서의 파라미터 값

**3. 동작 과정:**
1. 초기 파라미터 값을 설정합니다.
2. 손실 함수의 기울기(gradient)를 계산합니다: $\nabla J(\theta_{t})$.
   - 만약 기울기가 음수라면, 현재 파라미터 값에서 손실 함수의 값을 증가시키는 방향으로 이동합니다.
   - 반면에 기울기가 양수라면, 현재 파라미터 값에서 손실 함수의 값을 감소시키는 방향으로 이동합니다.
3. 현재 위치에서의 기울기에 학습률을 곱하여 이동 거리를 조절하여 파라미터를 갱신합니다.
   - 학습률은 파라미터 업데이트의 크기를 조절합니다. 너무 작으면 수렴에 시간이 오래 걸리고, 너무 크면 발산할 수 있습니다.
4. 위 과정을 반복하며 손실 함수의 값을 최소화하는 파라미터를 찾습니다.

## **역전파 (Backward Pass)** 

역전파 단계에서는 각 층에서의 그래디언트를 계산하고 이전 층으로 전파하여 가중치와 편향을 업데이트합니다.


1. **출력층 그래디언트 계산**:
   - 출력층의 그래디언트는 손실 함수 $L$을 해당 뉴런의 출력 $a^{(3)}$에 대해 미분한 것입니다.
   - 이를 행렬 연산으로 표현하면 다음과 같습니다:

     $$\frac{\partial L}{\partial z^{(3)}} = \nabla_{a^{(3)}} L \odot \sigma'(z^{(3)})$$

   여기서 $\nabla_{a^{(3)}} L$는 손실 함수 $L$을 $a^{(3)}$에 대해 미분한 결과이고, $\odot$는 요소별 곱을 나타냅니다.

2. **출력층 파라미터 업데이트**:
   - 출력층의 가중치와 편향에 대한 그래디언트를 계산하기 위해 입력값과 출력층 그래디언트를 곱합니다.
   - 이를 행렬 연산으로 나타내면 다음과 같습니다:

     $$\frac{\partial L}{\partial W^{(3)}} = a^{(2)T} \frac{\partial L}{\partial z^{(3)}}$$
     $$\frac{\partial L}{\partial b^{(3)}} = \frac{\partial L}{\partial z^{(3)}}$$

   여기서 $W^{(3)}$는 출력층의 가중치 행렬이고, $b^{(3)}$는 출력층의 편향 벡터입니다. $a^{(2)T}$는 은닉층의 출력을 전치시킨 것을 나타냅니다.

3. **은닉층 그래디언트 계산 및 업데이트**:
   - 은닉층의 그래디언트를 계산하기 위해 출력층 그래디언트를 이전 층으로 전파합니다.
   - 은닉층의 그래디언트를 계산하기 위해 Chain Rule을 적용합니다.
   - 행렬 연산으로 표현하면 다음과 같습니다:

     $$\frac{\partial L}{\partial z^{(2)}} = \left( \frac{\partial L}{\partial z^{(3)}} W^{(3)T} \right) \odot \sigma'(z^{(2)})$$
     $$\frac{\partial L}{\partial W^{(2)}} = a^{(1)T} \frac{\partial L}{\partial z^{(2)}}$$
     $$\frac{\partial L}{\partial b^{(2)}} = \frac{\partial L}{\partial z^{(2)}}$$

   여기서 $W^{(2)}$는 은닉층의 가중치 행렬이고, $b^{(2)}$는 은닉층의 편향 벡터입니다. $a^{(1)T}$는 입력층의 출력을 전치시킨 것을 나타냅니다.

이러한 방식으로 역전파 과정에서 각 파라미터의 그래디언트를 계산하고 업데이트할 수 있습니다.